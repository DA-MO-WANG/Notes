###### 第一篇

​		讲了一个针对学习mysql的学习理念：原理先行</br>
​		于此对比的是有充足经验和能力的人，时间的有效积累下还是被淘汰，这说明还不够。离开原理只是累积经验，成长速度还是不够快。而建立在原理基础上的经验才是加速器。</br>
​		理念：原理先行——》先找到最初的原理、原型——〉逐步演化，一直演化到最上层</br>

###### 第二篇

​		学习理念：看一个事，要先从高纬度理解，这样可以鸟瞰全貌（高纬度能看到大环境，而大环境决定语意）-对立的是：一开始就直接陷入细节，然后被淹死了

​		举例：平时在使用mysql，我们只需要知道，要根据什么，返回什么，其他没必要在最简单的用途还不明了的时候，就去掉进内部执行过程这个深渊--刚开始就是应该这么想，想多了反而走错了

​		一条查询语句在MySQL内部的执行过程：</br>
​				2个大世界-6个组件：5 + 1：server层(公用的)、存储引擎层(插件式)</br>
​				客户端小人和**连接器**小人的互动：</br>
​						要想利用mysql就得先搭上桥梁，建立联系---这个得找连接器</br>
​						明面上是要用户名-密码，暗地里要过一个权限认证逻辑；走过了，然后连接状态就产生了--空闲超时参数timeout</br>
​						链接有两种情况，长连接就是如果有持续请求，就会一直使用不变的连结；短连接就是执行完几次就断开连接
​						经验之谈：因为连接的创建成本高，所以推荐长连接——》带来一个问题：占用内存会越来越大，因为内存不释放，直到连接断开才释放，最终导致oom——〉常规解决思路：</br>
​								1.定期断开长连接，或者在执行完一个非常占用内存的大查询后</br>
​								2.mysql5.7之后提供了一个功能：mysql_reset connection 来重新初始化（类似回到出厂状态，而不是裸机状态）</br>
​			 与**查询缓存**小人互动</br>
​					这是开始执行查询的开始，（就像人做开发一样，接到一个任务，首先做的不是敲代码，而是先看看过去是不是做过类似的，有没有现成代码，直接可以ctrl+v/c），这里缓存以key-value形式存储，key存储的是sql语句，value存储的是查询结果，如果在缓存中命中，就直接返回结果</br>
​					查询缓存这个功能弊大于利，适合于静态表环境，比如系统配置表；mysql8.0已经放弃了这个功能</br>
​				与**分析器**小人互动</br>
​						找不到缓存，只能老老实实往下走。要想执行，mysql得先弄明白要干什么。先是词法分析，拆出每个词代表什么意思；然后是语法分析，符合不符合语法规定</br>
​				与**优化器**互动</br>
​						前面是知道要干什么了，接下来确定执行方案。其实mysql内部和我们人的想的那样唯一死板还不同，它并没有要求规定死了用什么顺序，而人为了唯一确定，自己添加了很多限制。比如有多个索引，选择用那个索引，这个没有死的规则，比如连接多张表，从哪个表入手，理论上都可以。但是要经过优化器的优化选择标准，最终确定一个方案
​				与**执行器**互动</br>
​						先判断对这个表有没有相应的权限</br>
​						打开表，利用引擎存储的接口，来读取表的第一行，满足条件存到结果集（先取再判断）</br>	
​						如果有索引，则取满足条件的第一行（这里不一样，提前先做判断了，直接取符合条件的）</br>				

​		mysql常识：</br>
​				具体的存储引擎不止一个，InnoDB(5.5后默认)、MyISAM、Memory-----建表时，用engine=？来指定

- -----------------------------------------------------------*-我的节奏：我每次状态时间在1/3一页，45*3=135，1h至少有一次沉浸，一天至少8次，大概15天一轮*

  ​     

  ###### 一条更新语句是如何执行的

  ​		更新语句除了走查询语句那一套，还多了东西：两个日志-redo重做日志/bin归档日志
  ​		redo日志，怎么理解？
  
  ​				引擎层面的日志，专属于innodb
  
  ​				作者这个赊账账本的例子很好。更新语句不是实时更新的，而是先把这个操作记录在一个临时位置上，在另一个时间再写入磁盘——》提高效率，在压力小的时候再执行写入操作
  ​				WAL技术，wtrite ahead logging  先写日志——》三个要素：日志、内存、磁盘
  ​						先把记录写到redo日志里，更新内存---暂时完成了
  ​						等到系统空闲，引擎会把记录更新到磁盘
  ​				问题：日志是固定大小的，如果满了，那就先把一部分日志更新到磁盘，然后腾出日志空间记录
  ​							write pos-记录位置指针  与 check point-擦除位置指针 --crash safe 能力
  ​		binlog日志，怎么理解？
  
  ​				server层面的日志
  ​						与redo log对比：
  ​								层面不同
  ​								内容形式不同：redo 是物理日志，记录的是物理形式的数据页上的改动；binlog是逻辑日志，逻辑的形式来记录，比如sql语句
  ​								写入规则不同，redo是循环写入，有覆盖的情况出现；binlog是追加形式，满了就会切换新的一个
  ​				更新语句的内部执行过程：
  ​						1.执行器要取id=2这一行
  ​						2.先去内存中看有没有，没有从磁盘中IO一次读到内存
  ​						3.执行更新操作，写入到内存的行数据中
  ​						4.写入redolog , redo处于prepare状态
  ​						5.写入bin log，把bin log持久化
  ​						6.调用引擎执行事务提交接口，把redo log改成commit状态	
  ​				两阶段提交机制：
  ​						如果redo写在立即提交，很容易出现，各种数据不一致问题。比如先写redo ，在写bin之前挂了，那么redo生效的，数据库的值已经改了，但是当利用binlog恢复数据时，就会少一次更新。临时库与真实库不一致——》比如误操作恢复场景；备库操作时
  ​				如何保证mysql异常重启后数据不丢失？
  ​						innodb_flush_log_at_trx_commit 设为1：每次事务redo log都持久化到磁盘
  ​				如何保证mysql异常重启后，binlog不丢失？
  ​						sync_binlog设为1:每次事务都持久化到磁盘	



###### 事务隔离

​	  	事务：这是一种概念，不是一种实体。这种概念表述几个操作被捆绑成一个事务，效果类似串联电路，一个失效时，其他也不能生效，全部生效时，才有生效效果
​			事务是在引擎层实现的
​			Innodb引擎层面的事务：
​					事务的特性：ACID，原子性、一致性、隔离性、持久性
​					隔离性有关的问题：
​							多个事务同时执行时，就会出现并发问题。比如脏读、不可重复读、换读——解决这些问题，所以有了隔离级别解决方案。
​							具体的隔离级别有：
​									读未提交：一个事务下未提交的变更可以被其他事务读到 
​									读已提交：只有提交后才能读到
​									可重复读：一个事务生命周期内，读到的保证一致
​									串行化：加锁，一个事务读的时候，其他不能写，一个写的时候，其他不能读
​					每一种隔离级别都有自己需要的场景---选择隔离级别千万不能脱离场景

​					可重复读隔离级别的实现：
​							针对同一个字段，每个更新操作，都伴随一条回滚记录。组成一段回滚日志。——》术语：多版本并发控制MVCC
​							每个事务启动，伴随不同视图 read-view

​					为什么不推荐使用长事务？
​							长事务意味着老事务视图，事务只要还没提交，所涉及到的回滚记录就得保留，这就需要占用大量空间。
​					如何正确启动事务，避免长事务？
​							set autocommit = 0 ，这个关闭自动提交的指令容易导致长事务。因为你忘了主动执行commit或rollback就会导致意外长事务。
​							建议使用 set. Auto commit =1 显式启动事务。这样就得来一套：bei gin/start. Transaction.  ------  commit
​							对于频繁使用事务的业务，可以使用 commit work. and chain. 这样就省去了第二次的begin
​							如何查询长事务？
​							在information_schema库里的innodb_trx表中查询：比如查询超过60s:
​									select * from information_schema.innodb_trx where  TIME_TO_SEC(timediff(now(),trx_started)) > 60

###### 索引-理论逻辑上												

​		面试问索引，其实就是问数据结构、问算法评估。尤其是在考察索引原理层面上。
​		索引，为了提升查询效率而出现的概念。索引在数据结构选型上的考量还考虑了写效率。（CRUD的本质简化为读写两种场景）
​		常见的三种选型：
​				hash表
​						从外面的抽象来看：key存储一个关键值特征，value维护一个记录；从内部细节来看，key 哈希到一个位置N，这个位置N存放详细记录。但是会出现哈希冲突现象。这个靠拉链来解决。
​						这种结构的优缺点，就看这种结构适不适配数据库场景。
​								增加数据/插入时很方便——》无序就不用维护有序，只需要追加
​								范围查询/区间查询时就相对有序数组很慢——〉因为无序需要全表遍历，有序省去了端点值后面的那部分遍历
​								===》这种结构只适用于等值查询，比如memcached\一些nosql
​				有序数组
​						无论什么操作，都不破坏有序特性

​						范围查询特比方便——》二分法可以以logn的复杂度来实现-优于hash表的一面
​						考虑写场景，维护有序特性，需要付出代价：要移动一些后置元素-复杂度on
​						====>他适用于静态存储场景，不存在更新变化的表

​				二叉搜索树					

​						查询时维护了另类的有序规则，可以减少点成本；增加时也是追加的形式---上面的两个问题都得到了一定改善，都是logn级别

​						从与磁盘的IO角度考虑(脱离本身逻辑层面的改进，与外界交互上改进)	:
​								磁盘每次访问一个数据块的寻址时间是10ms,  所以减少访问次数是一种优化路径。树的高度影响搜索路径长短，搜索路径与IO次数有关。所欲减少树的高度是一种方式，而树的高度与叉的数量有关，叉越多树越短。所以N叉树相比二叉更高效。
​						

###### 索引--偏实战层面		

​		索引是在引擎层实现的概念（架构上）
​		数据，最本真的存在形式还是磁盘页存储。索引只是一种引用逻辑，他不是直接操控的磁盘页，而是通过巧妙的组织引用/组织指针来提升效率。索引模型的实现就是讨论指针的组织形式。
​		innodb引擎的索引选择的是B+树。
​		索引怎么使用：
​				建表场景：主键--在字段定义后加primary key;  非主键--在字段定义最后用 index(字段)
​		
​	   索引树---》innodb存在两类索引树，一种对应主键索引，一种对应非主键索引
​	   靠叶子节点的内容来区分是主键还是非主键：
​							