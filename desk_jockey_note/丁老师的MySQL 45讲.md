####第一课

```shell
#第一次相识
讲了一个针对学习mysql的学习理念：原理先行
		于此对比的是有充足经验和能力的人，时间的有效积累下还是被淘汰，这说明还不够。离开原理只是累积经验，成长速度还是不够快。而建立在原理基础上的经验才是加速器。
		理念：原理先行——》先找到最初的原理、原型——〉逐步演化，一直演化到最上层
```

一个观念，学会推理，之所以要掌握原理，是因为认识到细节无穷无尽，把细节当作方向，只会最终累死。所以掌握相对关键的，源头的部分，再加上推理，就能拿到八成原貌。

####第二课

1. 看的角度：从外到内，从大到小，从表及里，先有一个大概的认识

   * mysql 也是c/s的软件应用架构。client是用户接触的部分，server是实际执行提供功能的部分，<font color=#F00000>外加存储引擎层</font>

   * server 涉及了用户想应用的各种功能背后的服务设计，包括连接器、查询缓存、分析器、优化器、执行器

   * 存储引擎层涉及多种类型的存储引擎，不同的存储引擎涉及不同的数据存储方式

2. 一个查询流程，背后走了什么样的路径，发生了什么样的事？

   * client这个客人，要做什么事，在正题之前，先得试探、礼仪一下，这里涉及的第一个接待人是<font color=#F0100>连接器</font>：主要包括处理建立连接的事务、权限鉴权的事务(这里和很多地方的连接状态的设计大同小异，比如三次握手，这类，目的是连接手续)

     ```sql
     #连接命令
     mysql -h localhost -u root -p
     #经历tcp后，走连接认证逻辑，搜权限表，定下权限来
     #还涉及长连接和短连接的状态
     #为了避免频繁创建连接，建议使用长连接
     ```

     * <font color=#F00000>问题1:</font>长连接，长时间运行临时内存越来越大，会让mysql容易出现OOM，也就是异常重启，这个问题怎么解决？
       * 定期断开长连接，或者当执行一个占用内存特别大的操作时，就断开连接，下次用的时候再重连
       * mysql高版本，会有mysql_reset_connection来重新初始化连接资源，这种手段不需要重新创建连接状态，也不需要走权限验证逻辑，只是恢复到最开始的状态

   * 查询缓存，弊大于利，一般适用于静态表多的场景

   * 寒暄完之后，开始切入正题-<font color=#F00000>分析器</font>。先得弄清楚client说得是什么。这里设计词法分析、语法分析。词法分析是结构映射，啥是表，啥是列；语法分析，是一套检验规则，看看有没有错误==>弄清楚你要做什么事

   * 弄清楚要做什么，然后是怎么去做。这里是<font color=#f0000>优化器</font>。它做的是确定执行策略。比如存在索引的话，先走哪个索引，有表连接的话，选择连接的顺序

   * 前面都不涉及数据，前面把一些前奏的东西处理完，就开始实际执行了。也就是<font color= #f0000>执行器</font>,它涉及去表里实际拿数据

     * 在打开表数据前，会有权限验证的环节
     * 引擎接口提供读取数据的一行，满足就放进结果集
     * 慢查询rows_examined字段显示一个语句的执行扫描了多少行



####第三课

一张表的定义信息：什么定义一张表：首先得有个标识表的东西-表名；然后表的结构由字段维系的，字段自然有字段的标识信息，字段具体的数据的类型信息，如何操作字段的控制信息

更新操作绕不开的两个日志模块设计：

* 很多设计都能在生活历史中找到原型，软件也是。看不见的思路是不受表象限制的
* 粉板和账本的配合：先是够不够的问题，不仅限于粉板、也不仅限于账本，取决于这两个因素。这种东西在生活场景中用来解决赊账问题，赊账方式可以促进消费。而如果只有账本的话，随着数量越来越多，就会耗损很大成本在找到对应记录上。如果只有粉板更不行，因为粉板虽然擦除速度快，但容量有限，在忙的时候记录在粉板上，一天的量是有限的，在不忙的时候，然后记录在账本上。这样的中间-异步思路很好解决了矛盾问题。
* 类似，mysql也是如此场景。mysql的更新操作，实际上并不是每一条的改动都同步在磁盘上改动的，这里面就有一个类似粉板的设计，就是redo日志，涉及的技巧是WAL技术，在写之前先记日志。也就是发生更新操作时，先记录在日志上，然后更新内存，等到空闲时再更改磁盘

​		mysql常识：</br>
​				具体的存储引擎不止一个，InnoDB(5.5后默认)、MyISAM、Memory-----建表时，用engine=？来指定

- -----------------------------------------------------------*-我的节奏：我每次状态时间在1/3一页，45*3=135，1h至少有一次沉浸，一天至少8次，大概15天一轮*

  ​     

  ###### 一条更新语句是如何执行的

  ​		更新语句除了走查询语句那一套，还多了东西：两个日志-redo重做日志/bin归档日志
  ​		redo日志，怎么理解？
  
  ​				引擎层面的日志，专属于innodb
  
  ​				作者这个赊账账本的例子很好。更新语句不是实时更新的，而是先把这个操作记录在一个临时位置上，在另一个时间再写入磁盘——》提高效率，在压力小的时候再执行写入操作
  ​				WAL技术，wtrite ahead logging  先写日志——》三个要素：日志、内存、磁盘
  ​						先把记录写到redo日志里，更新内存---暂时完成了
  ​						等到系统空闲，引擎会把记录更新到磁盘
  ​				问题：日志是固定大小的，如果满了，那就先把一部分日志更新到磁盘，然后腾出日志空间记录
  ​							write pos-记录位置指针  与 check point-擦除位置指针 --crash safe 能力
  ​		binlog日志，怎么理解？
  
  ​				server层面的日志
  ​						与redo log对比：
  ​								层面不同
  ​								内容形式不同：redo 是物理日志，记录的是物理形式的数据页上的改动；binlog是逻辑日志，逻辑的形式来记录，比如sql语句
  ​								写入规则不同，redo是循环写入，有覆盖的情况出现；binlog是追加形式，满了就会切换新的一个
  ​				更新语句的内部执行过程：
  ​						1.执行器要取id=2这一行
  ​						2.先去内存中看有没有，没有从磁盘中IO一次读到内存
  ​						3.执行更新操作，写入到内存的行数据中
  ​						4.写入redolog , redo处于prepare状态
  ​						5.写入bin log，把bin log持久化
  ​						6.调用引擎执行事务提交接口，把redo log改成commit状态	
  ​				两阶段提交机制：
  ​						如果redo写在立即提交，很容易出现，各种数据不一致问题。比如先写redo ，在写bin之前挂了，那么redo生效的，数据库的值已经改了，但是当利用binlog恢复数据时，就会少一次更新。临时库与真实库不一致——》比如误操作恢复场景；备库操作时
  ​				如何保证mysql异常重启后数据不丢失？
  ​						innodb_flush_log_at_trx_commit 设为1：每次事务redo log都持久化到磁盘
  ​				如何保证mysql异常重启后，binlog不丢失？
  ​						sync_binlog设为1:每次事务都持久化到磁盘	



###### 事务隔离

​	  	事务：这是一种概念，不是一种实体。这种概念表述几个操作被捆绑成一个事务，效果类似串联电路，一个失效时，其他也不能生效，全部生效时，才有生效效果
​			事务是在引擎层实现的
​			Innodb引擎层面的事务：
​					事务的特性：ACID，原子性、一致性、隔离性、持久性
​					隔离性有关的问题：
​							多个事务同时执行时，就会出现并发问题。比如脏读、不可重复读、换读——解决这些问题，所以有了隔离级别解决方案。
​							具体的隔离级别有：
​									读未提交：一个事务下未提交的变更可以被其他事务读到 
​									读已提交：只有提交后才能读到
​									可重复读：一个事务生命周期内，读到的保证一致
​									串行化：加锁，一个事务读的时候，其他不能写，一个写的时候，其他不能读
​					每一种隔离级别都有自己需要的场景---选择隔离级别千万不能脱离场景

​					可重复读隔离级别的实现：
​							针对同一个字段，每个更新操作，都伴随一条回滚记录。组成一段回滚日志。——》术语：多版本并发控制MVCC
​							每个事务启动，伴随不同视图 read-view

​					为什么不推荐使用长事务？
​							长事务意味着老事务视图，事务只要还没提交，所涉及到的回滚记录就得保留，这就需要占用大量空间。
​					如何正确启动事务，避免长事务？
​							set autocommit = 0 ，这个关闭自动提交的指令容易导致长事务。因为你忘了主动执行commit或rollback就会导致意外长事务。
​							建议使用 set. Auto commit =1 显式启动事务。这样就得来一套：bei gin/start. Transaction.  ------  commit
​							对于频繁使用事务的业务，可以使用 commit work. and chain. 这样就省去了第二次的begin
​							如何查询长事务？
​							在information_schema库里的innodb_trx表中查询：比如查询超过60s:
​									select * from information_schema.innodb_trx where  TIME_TO_SEC(timediff(now(),trx_started)) > 60

###### 索引-理论逻辑上												

​		面试问索引，其实就是问数据结构、问算法评估。尤其是在考察索引原理层面上。
​		索引，为了提升查询效率而出现的概念。索引在数据结构选型上的考量还考虑了写效率。（CRUD的本质简化为读写两种场景）
​		常见的三种选型：
​				hash表
​						从外面的抽象来看：key存储一个关键值特征，value维护一个记录；从内部细节来看，key 哈希到一个位置N，这个位置N存放详细记录。但是会出现哈希冲突现象。这个靠拉链来解决。
​						这种结构的优缺点，就看这种结构适不适配数据库场景。
​								增加数据/插入时很方便——》无序就不用维护有序，只需要追加
​								范围查询/区间查询时就相对有序数组很慢——〉因为无序需要全表遍历，有序省去了端点值后面的那部分遍历
​								===》这种结构只适用于等值查询，比如memcached\一些nosql
​				有序数组
​						无论什么操作，都不破坏有序特性

​						范围查询特比方便——》二分法可以以logn的复杂度来实现-优于hash表的一面
​						考虑写场景，维护有序特性，需要付出代价：要移动一些后置元素-复杂度on
​						====>他适用于静态存储场景，不存在更新变化的表

​				二叉搜索树					

​						查询时维护了另类的有序规则，可以减少点成本；增加时也是追加的形式---上面的两个问题都得到了一定改善，都是logn级别

​						从与磁盘的IO角度考虑(脱离本身逻辑层面的改进，与外界交互上改进)	:
​								磁盘每次访问一个数据块的寻址时间是10ms,  所以减少访问次数是一种优化路径。树的高度影响搜索路径长短，搜索路径与IO次数有关。所欲减少树的高度是一种方式，而树的高度与叉的数量有关，叉越多树越短。所以N叉树相比二叉更高效。
​						

###### 索引--偏实战层面		

​		索引是在引擎层实现的概念（架构上）
​		数据，最本真的存在形式还是磁盘页存储。索引只是一种引用逻辑，他不是直接操控的磁盘页，而是通过巧妙的组织引用/组织指针来提升效率。索引模型的实现就是讨论指针的组织形式。
​		innodb引擎的索引选择的是B+树。
​		索引怎么使用：
​				建表场景：主键--在字段定义后加primary key;  非主键--在字段定义最后用 index(字段)
​		
​	   索引树---》innodb存在两类索引树，一种对应主键索引，一种对应非主键索引
​	   靠叶子节点的内容来区分是主键还是非主键：
​				叶子节点的key是索引字段值，value如果存储行记录---主键索引；如果存储主键索引值---非主键索引
​		从效率上看，这两种查询有什么区分？
​					因为我们的目标是取到行数据。而主键树是直接关联行数据的，其他都是间接关联。所以从主键开始的只用走一棵树；其他至少走两棵树。后者也叫回表过程。走的树数量越少，自然更快



​		索引维护：
​				页分裂、页合并这些过程都会影响性能
​				业务场景分析：到底需不需要自增主键

​						两种选择：一种是拿自增主键；一种是拿业务逻辑字段做主键
​						业务逻辑字段做主键：适用k-v场景，不存在第二个索引，这种适合，可以利用到主键索引的优势
​						自增主键：适用保持有序特性的操作，同时考虑到索引key只是整数类型，不大，也适合和其他索引一起配合使用。

​			

面试题：如何避免长事务的影响？

​		应用开发端：
​				1.确认是否使用了set。auto commit = 0
​						可以在测试环境，把mysql的general_log开起来，随便跑一个业务逻辑，通过general_log日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，然后把它改为1；
​				2.找有没有不必要的只读事务。有些框架会习惯不管什么语句先用begin/commit框起来，这种只读事务可以去掉
​				3.业务连接数据库的时候，根据对业务的预估，通过set max_execution_time命令，控制每个语句的执行最长时间，避免单个语句意外执行太长。
​		

​			数据库端：
​					1.监控information_schema.innodb_trx表，设置长事务阈值，超过就报警/kill
​					2.Percona的pt-kill 工具
​					3.在业务功能测试阶段输出所有general_log，分析日志行为提前发现问题
​					4.如果是mysql 5.6版本以前，把innodb_undo_tablespaces设置成2，即使出现大事务回滚段过大，清理以后也方便。

