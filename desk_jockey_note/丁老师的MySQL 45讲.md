####第一课

```shell
#第一次相识
讲了一个针对学习mysql的学习理念：原理先行
		于此对比的是有充足经验和能力的人，时间的有效积累下还是被淘汰，这说明还不够。离开原理只是累积经验，成长速度还是不够快。而建立在原理基础上的经验才是加速器。
		理念：原理先行——》先找到最初的原理、原型——〉逐步演化，一直演化到最上层
```

一个观念，学会推理，之所以要掌握原理，是因为认识到细节无穷无尽，把细节当作方向，只会最终累死。所以掌握相对关键的，源头的部分，再加上推理，就能拿到八成原貌。

####第二课

1. 看的角度：从外到内，从大到小，从表及里，先有一个大概的认识

   * mysql 也是c/s的软件应用架构。client是用户接触的部分，server是实际执行提供功能的部分，<font color=#F00000>外加存储引擎层</font>

   * server 涉及了用户想应用的各种功能背后的服务设计，包括连接器、查询缓存、分析器、优化器、执行器

   * 存储引擎层涉及多种类型的存储引擎，不同的存储引擎涉及不同的数据存储方式

2. 一个查询流程，背后走了什么样的路径，发生了什么样的事？

   * client这个客人，要做什么事，在正题之前，先得试探、礼仪一下，这里涉及的第一个接待人是<font color=#F0100>连接器</font>：主要包括处理建立连接的事务、权限鉴权的事务(这里和很多地方的连接状态的设计大同小异，比如三次握手，这类，目的是连接手续)

     ```sql
     #连接命令
     mysql -h localhost -u root -p
     #经历tcp后，走连接认证逻辑，搜权限表，定下权限来
     #还涉及长连接和短连接的状态
     #为了避免频繁创建连接，建议使用长连接
     ```

     * <font color=#F00000>问题1:</font>长连接，长时间运行临时内存越来越大，会让mysql容易出现OOM，也就是异常重启，这个问题怎么解决？
       * 定期断开长连接，或者当执行一个占用内存特别大的操作时，就断开连接，下次用的时候再重连
       * mysql高版本，会有mysql_reset_connection来重新初始化连接资源，这种手段不需要重新创建连接状态，也不需要走权限验证逻辑，只是恢复到最开始的状态

   * 查询缓存，弊大于利，一般适用于静态表多的场景

   * 寒暄完之后，开始切入正题-<font color=#F00000>分析器</font>。先得弄清楚client说得是什么。这里设计词法分析、语法分析。词法分析是结构映射，啥是表，啥是列；语法分析，是一套检验规则，看看有没有错误==>弄清楚你要做什么事

   * 弄清楚要做什么，然后是怎么去做。这里是<font color=#f0000>优化器</font>。它做的是确定执行策略。比如存在索引的话，先走哪个索引，有表连接的话，选择连接的顺序

   * 前面都不涉及数据，前面把一些前奏的东西处理完，就开始实际执行了。也就是<font color= #f0000>执行器</font>,它涉及去表里实际拿数据

     * 在打开表数据前，会有权限验证的环节
     * 引擎接口提供读取数据的一行，满足就放进结果集
     * 慢查询rows_examined字段显示一个语句的执行扫描了多少行



####第三课

一张表的定义信息：什么定义一张表：首先得有个标识表的东西-表名；然后表的结构由字段维系的，字段自然有字段的标识信息，字段具体的数据的类型信息，如何操作字段的控制信息

更新操作绕不开的两个日志模块设计：

* 很多设计都能在生活历史中找到原型，软件也是。看不见的思路是不受表象限制的
* 粉板和账本的配合：先是够不够的问题，不仅限于粉板、也不仅限于账本，取决于这两个因素。这种东西在生活场景中用来解决赊账问题，赊账方式可以促进消费。而如果只有账本的话，随着数量越来越多，就会耗损很大成本在找到对应记录上。如果只有粉板更不行，因为粉板虽然擦除速度快，但容量有限，在忙的时候记录在粉板上，一天的量是有限的，在不忙的时候，然后记录在账本上。这样的中间-异步思路很好解决了矛盾问题。
* 类似，mysql也是如此场景。mysql的更新操作，实际上并不是每一条的改动都同步在磁盘上改动的，这里面就有一个类似粉板的设计，就是redo日志，涉及的技巧是WAL技术，在写之前先记日志。也就是发生更新操作时，先记录在日志上，然后更新内存，等到空闲时再更改磁盘
  * 引擎层的redo log设计：固定大小，通常可以配置具体文件数，没个文件的大小；两个指针，一个记录当前写的位置，一个是记录擦除的位置，整个是__循环写__的==》crash-safe能力
    * 总是说这个是物理的，其实针对的是页，记录的是页层面的改动
    * redo log 是InnoDB独有的，换了其他引擎，就没有了，引擎层操作的是这个log
    * 循环写，这个由两个指针的设计就能看出来
    * innodb_flush_log_at_trx_commit 参数设为1，每次事务都持久化磁盘
  * server层的bin log设计：
    * bin log 体现的是逻辑层面的记录，记录的是语义逻辑
    * server层面的执行器操作的是redo log
    * 追加写，写满了就换一个新文件，也就意味着这个没有固定大小
    * sync_binlog设置1，每次事务binlog 也持久化磁盘
  * 两阶段提交：redo log的prepare 和 commit状态
    * 引擎把更新操作记录在redo log，redo log 处于prepare状态—准备好提交事务的信号
    * 执行器调用引擎的提交事务接口，引擎把redo log改成commit状态
    * 在prepare和commit之间是执行器生成这个binlog，并写入磁盘
  * 某天下午2点发现到中午十二点的有一次误删表，需要找回数据，怎么做？
    * 先找到最近的一次全量备份，然后恢复到临时库
    * 找到备份的binlog，找到出问题的那个时刻
  * 为什么需要两阶段提交？为什么redo 和 bin 混在一起
    * 其实和事务的作用一样，主要是应对利用日志恢复数据的场景时，防止出现恢复出的不是原来数据的问题。如果先写redo log 后写bin log，在redo 完成后，bin写到一半，就crash了，mysql自己重启会按照redo来恢复，这个效果就是执行操作后的值；如果后续再有备份的需要时，利用bin 恢复时，bin没记录，所以会丢失一次更新==》redo bin 不一致对应 mysql 重启后的状态和备份后的状态不一致
    * 先写bin 后写 redo ，也是一个道理。只不过因为redo没记录，异常重启后没有状态；但是bin记录了，等到备份恢复时，就多了一次本来不应该存在的更新
  * 全量备份的周期策略，如何决定？是一周一备还是一天一备？
    * 一周一备，就得保证这一周内具体时间点的bin log都得完整，否则没法恢复，压力在bin log的写入的保证
      * 两个思考角度：最坏情况下的恢复目标时间
      * 考虑业务重要性和存储成本
    * 一天一备，相对要求这一天的binlog 完整，压力在备份的压力
  * 这个事务设计，在很多场景中都会用到

#### 第四课

在现实生活中，事务概念很重要。很多日常生活中的业务场景都需要事务概念支持。事务概念，简单来讲，就是一组操作，保证最后的状态要么是完全原点，要么是成功状态。只有这两种状态。对应操作上，要么是全部成功，要么全部回退。

事务并不是新的操作语句，而是一个防护罩，在原有的操作语句下，在外面套上了一层东西，主要考虑的并发之间的相互影响

事务支持是在引擎层实现的，但不是所有引擎都支持事务。

1. 事务涉及的相关概念

   * 事务的四个特性：ACID

     * 隔离性Isolation

       当事务出现并发执行时，就会带出并发问题，在数据库中常见的并发问题有：脏读dirty read、不可重复读 non-repeatable read、幻读 phantom read

       * 隔离级别的概念

         隔离的程度建立在牺牲效率的前提下，这里的隔离指事务之间相互影响的程度，确切地说事务各自处理的数据的相互影响程度

         * 四个隔离级别
           * 读未提交 read uncommitted
             * 两个事务混在一起，对数据的任何改变，对两个事务都是公开可见的
           * 读已提交 read committed
             * 一个事务对数据的变动，只有当它提交后，才对其他事务可见，否则就是他自己的可见域
           * 可重复读 reapetable read
             * 其他事务对数据的更改，对当前事务是没有干扰的。在这个级别下，每个事务开辟自己的小空间，其他事务对数据的变动无论是否提交，都看不到，自己操作的还是自己启动事务时看到的数据情况。只有自己提交事务后，才能看到公开域。不提交，自己的眼睛只能活在自己的可见域内
           * 串行化 serializable
             * 通过对一行记录加读写锁，来彻底隔离事务，不存在同一行数据在同一个时刻被多个事务操作，一女只侍一夫
         * ![image-20220411085355246](丁老师的MySQL 45讲.assets/image-20220411085355246.png)

两条并行的时间线，不同隔离级别约束下，能看到的V1、V2、V3各不相同

实现原理：

* 最初始的状态就是读未提交，这个时候没有任何额外的东西，每个事务对记录的修改都是透明的
* 然后是视图这个东西的创建点和事务启动时间点、sql语句执行点的先后顺序
  * 视图伴随事务启动创建，事务就会用这个视图----可重复读的效果
  * 视图在每个sql语句执行粒度创建---读提交隔离级别？？？？？待定

* 串行化，不是在数据上做手脚了，而是通过加锁来在访问上做手脚

如何配置隔离级别？改变启动参数transaction_isolation![image-20220411150516005](丁老师的MySQL 45讲.assets/image-20220411150516005.png)

2. MVCC多版本并发控制

   一条记录的修改，会伴随一个历史记录链，用来回滚时用-事务失败时就会回滚，到时🫴这个回滚日志来实现

   这时涉及一个问题，事务特别长，相应的回滚日志就特别大，在事务提交前，回滚记录必需保留，就会有占空间特别大的问题

3. 长事务带来的问题

    回滚段的影响、占用锁资源

    如何避免长事务？

   * 事务的启动方式

     * 如果是set autocommit = 0, 这个命令意思是关闭了自动提交，除非显式提交，否则所有操作都在事务中，自动启动事务
     * 建议使用set autocommit = 1, 启动和提交都显式，考虑交互次数，可以用commit work and chain来代替commit，这样提交后，会自动开启下一个事务

   * 排查长事务的命令
     ```sql
     -- 在information_schema库下innodb_trx表中，找事务持续时间>60s的记录
     select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
     ```

4. 如果你是负责人，如何处理长事务的情况，有没有什么方案？

* 应用开发端来看

  * 确认是否使用了set autocommit=0
    * 打开mysql的general_log日志，跑一个业务逻辑，通过这个日志确认这个值，然后改成1

  * 确认是否有没有没必要的只读事务
  * 预估业务本身耗费时间，设置set max_execution_time命令控制每个语句执行的最长时间，避免单个语句执行最长时间

* 数据库端来看

  * 

能避免尽量避免，如果无法避免，就要保证日志空间足够，支持动态空间 增长，同时监控innodb_trx这个表，触发底线时间就报警

####第五课、第六课

1. 理论

索引有利于提高数据查询效率，类似目录之于书。本质是借助索引查询的路径成本远短于没有任何技巧的查询

索引改变的是起点数据和终点数据的组织形式，但这只是一个模型特点，基于这种特点并不意味一种实现方式。相反，索引模型有很多种实现方式，基于不同读写效率，对应有不同的数据结构。

* 哈希结构

  * 完整的数据作为值存储在数组里，对完整数据做一个摘要，映射到数组索引，决定值存储的位置
  * 因为哈希映射并不具有传递单调性，所以添加随意添加，也就是不保证有序性，当做范围查询时，因为无法借助有序性，使用二分，所以只能暴力扫描，很慢==》基于这种特点，只适合等值查询

* 二叉搜索树

  * 本身结构带有顺序性，查询复杂度是Ologn, 当然越平衡，复杂度越趋近Ologn
  * 经过的路径节点数是log 叉数  2* 数据行数，以二叉树为例，100万行数据，因为路径要延伸就得不断去比对，所以要IO20个数据块，每个数据块IO时间10ms，一行数据就得需要200ms，不能接受==》考虑N叉树，比如InnoDB中N大概是1200，那么如果树高为4就能存储1200 的4次幂除以1200，大概17亿数据（liuyuboo中讲过这个特点，所以相对容易接受），最多4次IO

  * 也就是重操作集中在IO磁盘次数上了，谁能降低这个次数，谁就是更好的实现结构

2. 实战：InnoDB索引模型为例

   * InnoDB使用了B+树索引模型，每一个索引对应一颗B+树
   * 主键索引叶子结点存储的是，key: 主键值；value：整行数据
   * 非主键索引叶子结点存储的是，key:非主键值；value：对应的主键字段值
   * 通过主键查询，只涉及搜索一颗主键对应的树；通过普通索引查询，会先找普通索引对应树找到对应的主键字段值，然后回到主键索引对应的树，找到整行数据===》前者只涉及一棵树，后者两棵树，所以都可以是推荐使用主键索引
   * 索引维护
     * 对数据的增删，会带来索引树的变化，还涉及页分裂、页分裂带来的合并，这些都是性能影响区
     * 自增主键的好处，就是添加操作只会追加,系统会获取当前字段最大值加1作为下一条记录的ID值：建表命令==》在主键命令后面添加AUTO_INCREMENT
     * 问题：业务字段做主键索引还是自增主键做主键索引，如何取舍？
       * 因为非主键索引的叶子结点存储的是主键索引的字段值，如果主键索引采用的是空间占用量大的选择，就会造成占用空间大的问题，所以问题的关键在哪一种选择字段占用空间小
       * 如果是典型的kv场景，为了方便业务，也不存在什么其他索引，这个时候可以用业务字段作为索引
     * 

   













​		mysql常识：</br>
​				具体的存储引擎不止一个，InnoDB(5.5后默认)、MyISAM、Memory-----建表时，用engine=？来指定

- -----------------------------------------------------------*-我的节奏：我每次状态时间在1/3一页，45*3=135，1h至少有一次沉浸，一天至少8次，大概15天一轮*

  ​     

  ###### 一条更新语句是如何执行的

  ​		更新语句除了走查询语句那一套，还多了东西：两个日志-redo重做日志/bin归档日志
  ​		redo日志，怎么理解？
  
  ​				引擎层面的日志，专属于innodb
  
  ​				作者这个赊账账本的例子很好。更新语句不是实时更新的，而是先把这个操作记录在一个临时位置上，在另一个时间再写入磁盘——》提高效率，在压力小的时候再执行写入操作
  ​				WAL技术，wtrite ahead logging  先写日志——》三个要素：日志、内存、磁盘
  ​						先把记录写到redo日志里，更新内存---暂时完成了
  ​						等到系统空闲，引擎会把记录更新到磁盘
  ​				问题：日志是固定大小的，如果满了，那就先把一部分日志更新到磁盘，然后腾出日志空间记录
  ​							write pos-记录位置指针  与 check point-擦除位置指针 --crash safe 能力
  ​		binlog日志，怎么理解？
  
  ​				server层面的日志
  ​						与redo log对比：
  ​								层面不同
  ​								内容形式不同：redo 是物理日志，记录的是物理形式的数据页上的改动；binlog是逻辑日志，逻辑的形式来记录，比如sql语句
  ​								写入规则不同，redo是循环写入，有覆盖的情况出现；binlog是追加形式，满了就会切换新的一个
  ​				更新语句的内部执行过程：
  ​						1.执行器要取id=2这一行
  ​						2.先去内存中看有没有，没有从磁盘中IO一次读到内存
  ​						3.执行更新操作，写入到内存的行数据中
  ​						4.写入redolog , redo处于prepare状态
  ​						5.写入bin log，把bin log持久化
  ​						6.调用引擎执行事务提交接口，把redo log改成commit状态	
  ​				两阶段提交机制：
  ​						如果redo写在立即提交，很容易出现，各种数据不一致问题。比如先写redo ，在写bin之前挂了，那么redo生效的，数据库的值已经改了，但是当利用binlog恢复数据时，就会少一次更新。临时库与真实库不一致——》比如误操作恢复场景；备库操作时
  ​				如何保证mysql异常重启后数据不丢失？
  ​						innodb_flush_log_at_trx_commit 设为1：每次事务redo log都持久化到磁盘
  ​				如何保证mysql异常重启后，binlog不丢失？
  ​						sync_binlog设为1:每次事务都持久化到磁盘	



###### 事务隔离

​	  	事务：这是一种概念，不是一种实体。这种概念表述几个操作被捆绑成一个事务，效果类似串联电路，一个失效时，其他也不能生效，全部生效时，才有生效效果
​			事务是在引擎层实现的
​			Innodb引擎层面的事务：
​					事务的特性：ACID，原子性、一致性、隔离性、持久性
​					隔离性有关的问题：
​							多个事务同时执行时，就会出现并发问题。比如脏读、不可重复读、换读——解决这些问题，所以有了隔离级别解决方案。
​							具体的隔离级别有：
​									读未提交：一个事务下未提交的变更可以被其他事务读到 
​									读已提交：只有提交后才能读到
​									可重复读：一个事务生命周期内，读到的保证一致
​									串行化：加锁，一个事务读的时候，其他不能写，一个写的时候，其他不能读
​					每一种隔离级别都有自己需要的场景---选择隔离级别千万不能脱离场景

​					可重复读隔离级别的实现：
​							针对同一个字段，每个更新操作，都伴随一条回滚记录。组成一段回滚日志。——》术语：多版本并发控制MVCC
​							每个事务启动，伴随不同视图 read-view

​					为什么不推荐使用长事务？
​							长事务意味着老事务视图，事务只要还没提交，所涉及到的回滚记录就得保留，这就需要占用大量空间。
​					如何正确启动事务，避免长事务？
​							set autocommit = 0 ，这个关闭自动提交的指令容易导致长事务。因为你忘了主动执行commit或rollback就会导致意外长事务。
​							建议使用 set. Auto commit =1 显式启动事务。这样就得来一套：bei gin/start. Transaction.  ------  commit
​							对于频繁使用事务的业务，可以使用 commit work. and chain. 这样就省去了第二次的begin
​							如何查询长事务？
​							在information_schema库里的innodb_trx表中查询：比如查询超过60s:
​									select * from information_schema.innodb_trx where  TIME_TO_SEC(timediff(now(),trx_started)) > 60

###### 索引-理论逻辑上												

​		面试问索引，其实就是问数据结构、问算法评估。尤其是在考察索引原理层面上。
​		索引，为了提升查询效率而出现的概念。索引在数据结构选型上的考量还考虑了写效率。（CRUD的本质简化为读写两种场景）
​		常见的三种选型：
​				hash表
​						从外面的抽象来看：key存储一个关键值特征，value维护一个记录；从内部细节来看，key 哈希到一个位置N，这个位置N存放详细记录。但是会出现哈希冲突现象。这个靠拉链来解决。
​						这种结构的优缺点，就看这种结构适不适配数据库场景。
​								增加数据/插入时很方便——》无序就不用维护有序，只需要追加
​								范围查询/区间查询时就相对有序数组很慢——〉因为无序需要全表遍历，有序省去了端点值后面的那部分遍历
​								===》这种结构只适用于等值查询，比如memcached\一些nosql
​				有序数组
​						无论什么操作，都不破坏有序特性

​						范围查询特比方便——》二分法可以以logn的复杂度来实现-优于hash表的一面
​						考虑写场景，维护有序特性，需要付出代价：要移动一些后置元素-复杂度on
​						====>他适用于静态存储场景，不存在更新变化的表

​				二叉搜索树					

​						查询时维护了另类的有序规则，可以减少点成本；增加时也是追加的形式---上面的两个问题都得到了一定改善，都是logn级别

​						从与磁盘的IO角度考虑(脱离本身逻辑层面的改进，与外界交互上改进)	:
​								磁盘每次访问一个数据块的寻址时间是10ms,  所以减少访问次数是一种优化路径。树的高度影响搜索路径长短，搜索路径与IO次数有关。所欲减少树的高度是一种方式，而树的高度与叉的数量有关，叉越多树越短。所以N叉树相比二叉更高效。
​						

###### 索引--偏实战层面		

​		索引是在引擎层实现的概念（架构上）
​		数据，最本真的存在形式还是磁盘页存储。索引只是一种引用逻辑，他不是直接操控的磁盘页，而是通过巧妙的组织引用/组织指针来提升效率。索引模型的实现就是讨论指针的组织形式。
​		innodb引擎的索引选择的是B+树。
​		索引怎么使用：
​				建表场景：主键--在字段定义后加primary key;  非主键--在字段定义最后用 index(字段)
​		
​	   索引树---》innodb存在两类索引树，一种对应主键索引，一种对应非主键索引
​	   靠叶子节点的内容来区分是主键还是非主键：
​				叶子节点的key是索引字段值，value如果存储行记录---主键索引；如果存储主键索引值---非主键索引
​		从效率上看，这两种查询有什么区分？
​					因为我们的目标是取到行数据。而主键树是直接关联行数据的，其他都是间接关联。所以从主键开始的只用走一棵树；其他至少走两棵树。后者也叫回表过程。走的树数量越少，自然更快



​		索引维护：
​				页分裂、页合并这些过程都会影响性能
​				业务场景分析：到底需不需要自增主键

​						两种选择：一种是拿自增主键；一种是拿业务逻辑字段做主键
​						业务逻辑字段做主键：适用k-v场景，不存在第二个索引，这种适合，可以利用到主键索引的优势
​						自增主键：适用保持有序特性的操作，同时考虑到索引key只是整数类型，不大，也适合和其他索引一起配合使用。

​			

面试题：如何避免长事务的影响？

​		应用开发端：
​				1.确认是否使用了set。auto commit = 0
​						可以在测试环境，把mysql的general_log开起来，随便跑一个业务逻辑，通过general_log日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，然后把它改为1；
​				2.找有没有不必要的只读事务。有些框架会习惯不管什么语句先用begin/commit框起来，这种只读事务可以去掉
​				3.业务连接数据库的时候，根据对业务的预估，通过set max_execution_time命令，控制每个语句的执行最长时间，避免单个语句意外执行太长。
​		

​			数据库端：
​					1.监控information_schema.innodb_trx表，设置长事务阈值，超过就报警/kill
​					2.Percona的pt-kill 工具
​					3.在业务功能测试阶段输出所有general_log，分析日志行为提前发现问题
​					4.如果是mysql 5.6版本以前，把innodb_undo_tablespaces设置成2，即使出现大事务回滚段过大，清理以后也方便。

